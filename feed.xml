<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <title>blog</title>
    <link href="https://heyally.ai/blog/feed.xml" rel="self" />
    <link href="https://heyally.ai/blog" />
    <updated>2025-12-07T20:56:31-05:00</updated>
    <author>
        <name>Brian Gladu</name>
    </author>
    <id>https://heyally.ai/blog</id>

    <entry>
        <title>Ally macOS app gets native full screen mode support</title>
        <author>
            <name>Brian Gladu</name>
        </author>
        <link href="https://heyally.ai/blog/macos-full-screen-mode/"/>
        <id>https://heyally.ai/blog/macos-full-screen-mode/</id>
            <category term="updates"/>
            <category term="macos"/>

        <updated>2025-12-07T16:30:12-05:00</updated>
            <summary type="html">
                <![CDATA[
                    Long periods of unbroken concentration, that most of us require to achieve the deep focus that leads to “deep work,” are increasingly challenging to come by. We know our best work comes from focus, but it can be challenging to tailor our digital workspaces to&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <p>Long periods of unbroken concentration, that most of us require to achieve the deep focus that leads to “<a href="https://www.amazon.com/Deep-Work-Focused-Success-Distracted/dp/1455586692">deep work</a>,” are increasingly challenging to come by.</p><p>We know our best work comes from focus, but it can be challenging to tailor our digital workspaces to minimize distractions. In fact, they’re, at least in some ways, intentionally designed to capture and divert our attention away from whatever we’re doing, such as for alerts and notifications. There’s also a row of colorful icons tempting us to stray from our plan to focus. </p><p><a href="https://support.apple.com/guide/mac-help/use-apps-in-full-screen-mchl9c21d2be/mac">macOS’s full-screen mode</a> helps with focus and concentration. It minimizes distracting visual clutter by devoting the entire screen to a single app. This is an app experience that’s default behavior on Windows, but not macOS. Both modes have their uses and benefits. But, for deep work, work that requires prolonged focus to be productive, many of us benefit from things that eliminate distraction, like full-screen mode. For anyone on the difficult end of the ADHD spectrum, the “multi-task mode” that macOS encourages by default can actually be a productivity hindrance. </p><p>Now Ally supports full-screen mode so you can laser focus on whatever markdown doc you’re creating, web clipping you’re reading, or local AI chat you’re having. </p><p>To get started, <a href="https://apps.apple.com/us/app/ally-ai-for-life/id6752736179">download the latest version of the Ally AI app from the macOS app store</a>. </p><p>With the Ally app running, press the key combination <code>fn + f</code> or click the green circle icon in the upper left-hand corner of the app. </p><p>To exit full screen mode, you can press ‘esc’ or ‘fn + f’ or click the green circle icon that appears when you hover the upper left-hand corner of the app while in full screen mode.</p><p>You can also arrange the Ally app side by side with other apps, such as a web browser or PDF viewer, for research, by clicking and holding the green circle icon, then selecting one of the tile options to arrange the window. </p><p>Now you can focus better with fewer visual distractions competing for your attention. </p><p>I’ll continue looking for new ways to leverage Apple’s ecosystem to make productivity easier with Ally. If you have an idea, <a href="mailto:hi@heyally.ai">let me know</a> or <a href="https://ally.eververse.ai/">submit as a feature request</a> and I’ll add it to the community-driven roadmap. </p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>The state of running LLMs locally in 2026</title>
        <author>
            <name>Brian Gladu</name>
        </author>
        <link href="https://heyally.ai/blog/the-state-of-running-llms-locally-in-2026/"/>
        <id>https://heyally.ai/blog/the-state-of-running-llms-locally-in-2026/</id>
            <category term="ai"/>

        <updated>2025-12-07T15:40:19-05:00</updated>
            <summary type="html">
                <![CDATA[
                    If you’re excited to try out local models because you’re hoping it will be like running Claude or ChatGPT on your computer or phone, you’ll be disappointed. The models that can be run on consumer hardware are impressive for their size, but not competitive with&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <p>If you’re excited to try out local models because you’re hoping it will be like running Claude or ChatGPT on your computer or phone, you’ll be disappointed. The models that can be run on consumer hardware are impressive for their size, but not competitive with the massive frontier models on any benchmark and the experience isn’t comparable in terms of capabilities or polish.</p><p>However, this doesn’t and shouldn’t be taken as a slight against the open source community. In fact, it’s incredible what they’ve done and I’m a huge supporter of the open source AI community. It’s incredible. </p><p>But. I still think for expectation setting it’s important for people to know running Qwen3 locally isn’t going to be the same as chatting with GPT 5.1 or Opus 4.5. It’s going to be slower. It’s going to be less intelligent. It’s going to make more mistakes. These models are incredible for their size, it’s mind-bending that we have models as intelligent and capable as these running on our laptops, but these models aren’t trillions of parameters and consumer GPUs aren’t comparable to data centers, and that becomes apparent pretty fast after you get ollama or LMstudio installed.</p><p>It’s like “this is really cool that I can do this on my computer but ChatGPT is way better and way easier.” Fair. Correct on both counts.</p><p>However, just because a model cannot compete head to head against models above its weight class, that does not mean that smaller models cannot be applied and leveraged in ways that give comparable results and with a comparable or even better user experience.</p><p>One key principle is not asking a model to do more than it is capable of. That is, knowing and respecting its limits. You may be able to flood Gemini with a 800k textbook and chat with it, but you won’t be able to do that with GPT-OSS 20B. In fact, giving it just a dozen pages will slow the chat experience to a crawl.</p><p>That doesn’t mean a similar experience isn’t possible, it just means a different approach must be engineered and that could take a variety of forms:</p><ul>
<li>Multi-model intelligence - rather than utilizing a massive multi-modal model, the local approach instead utilizes a collection of models, chosen to respect the resources of the device, </li>
<li>Resource polling - devices pool resources across secure networks to create secure clusters that can be tapped into.</li>
<li>Input engineering - all context and prompts are optimized for maximal effectiveness at minimal tokens.</li>
<li>Workflow engineering - rather than simple input/output, a more complex process happens behind the scenes often involving processing, routing, and specialized agents with optional tools at their disposal. This can be very effective, and the experience good, when hundreds of tokens can be churned every second by a frontier models. Asking Qwen3 8b to run that workflow would take a lot longer, fail a lot more often, and offer a much lower quality experience.</li>
</ul>
<p>And at that point, it’s like “Well, I guess I’ll just pay the $20 or $40 a month it takes to have access to the best models.”</p><p>And that does make sense, for now.</p><p>Ally was created to change that. At The Bright Company we believe that secure, private local AI built on open source models and software can provide an experience that rivals and even exceeds what’s possible with OpenAI, Gemini, etc.</p><p>We don’t think the potential of open source models running on edge devices is tapped. In fact, we think it’s unexplored because so much is being invested in the race to AGI. </p><p>And, to be frank, the world needs a viable alternative to the major players who, frankly, have a track record of inserting ads where they’re unwelcome, mining user data without conscious, and in general exploiting their relationship with consumers. </p><p>AI is clearly a new kind of technology. At its best, it promises helpful companionship and “always there assistance” throughout life. Like that kids robot movie. We already know that the more you share with AI, the more helpful it can be. The logical extension of that is that if it has all context of your life, it can be very helpful. If it heard every sound, if it saw every detail, and could not only recall that info but was also constantly processing it for new ways to assist you with your future plans, that’d be amazing. It’d also mean giving Meta, or OpenAI, or Amazon access to literally your entire life. Sure, they can say it’s processed locally. They can say it won’t show you ads. And, you know what, 10 years after they have it in your home they only sell robots that will occasionally recommend certain brands when putting together your shopping list. We’ve been down this road before, so when the second or third wave of consumer robots are surprisingly cheap, don’t act like you don’t know how this plays out. </p><p>No thank you. Big tech has a very low standard for consumer respect and I do not want to be a part of it. It actually sickens me that pricing is driven by profit instead of value. That enshitifucation is a predictable thing as a once cool product loses its way as it tries to increase metrics and profits quarter after quarter year after year.</p><p>All that can be avoided by creating a product that simply does not collect consumer information. Period. You don’t even create an account. All your data stays local. Nothing is ever sent off your device. That means you can interact with AI without worrying that your new idea will be used as training data for the next model and then be shared with hundreds of people, that your chats with sensitive medical info or health topics will leak, that your chats won’t be used to sell you hyper targeted ads that take into account everything you’ve ever shared with that company and Ai, etc.</p><p>The Bright Company, the company behind Ally, me and my dog, Roach, and my wife gives a lot of input with I appreciate, created</p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Tools to connect to many LLMs at once</title>
        <author>
            <name>Brian Gladu</name>
        </author>
        <link href="https://heyally.ai/blog/tools-to-connect-to-many-llms-at-once/"/>
        <id>https://heyally.ai/blog/tools-to-connect-to-many-llms-at-once/</id>
            <category term="ai"/>

        <updated>2025-12-07T14:21:16-05:00</updated>
            <summary type="html">
                <![CDATA[
                    To access the latest frontier AI models from Anthropic, OpenAI, Google, Perplexity, and Deepseek, you could pay $100 or more in monthly subscriptions. A cost-saving alternative is to use an AI chat interface — sometimes referred to as a “chatbot UI” or “LLM frontend” (there doesn’t&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <p>To access the latest frontier AI models from Anthropic, OpenAI, Google, Perplexity, and Deepseek, you could pay $100 or more in monthly subscriptions. </p><p>A cost-saving alternative is to use an AI chat interface — sometimes referred to as a “chatbot UI” or “LLM frontend” (there doesn’t appear to be an agreed upon naming convention). These apps allow you to connect to LLMs via their APIs. This way, you pay only for your actual usage. </p><p>This approach has a few advantages:</p><ol>
<li><p><strong>Multi-model access</strong> - With a frontend UI you can access any model with an OpenAPI compatible API. You could be coding with Claude, then switch to Deepseek to plan your next vacation, then throw an enormous PDF at Gemini for some quick Q&amp;A. </p></li>
<li><p><strong>Cost-savings</strong> - What’s great about accessing LLMs via the API is that, for most people, it is much less expensive because you’re only paying for your actual usage. Unless you’re an extremely heavy user, you’ll probably find that your total API costs — across all models — ends up being less than $10 a month. </p></li>
<li><p><strong>Cool features</strong> - Chatbot UI’s tend to clone features added by the major players and will often explore experimental or highly speclialized new features you won’t find in any of the UIs of the major AI players. You’ll be able to run open source models locally, test multiple models side-by-side, easily add RAG to give your AI specialized knowledge, and more. </p></li>
<li><p><strong>Easier to manage</strong> - It’s much easier to manage prompts, system instructions, stored memories, and RAG databases from one place instead of needing to keep this kind of LLM context data consistent and up-to-date across the various LLM platforms.</p></li>
</ol>
<p>And this approach has downsides:</p><ol>
<li><p><strong>You’ll lose access to some of the specialized, unique features</strong> - The Perplexity UI has some great features like Projects and Pages. OpenAI’s desktop app can connect to apps you’re running locally so it can “see” what you’re doing. Sometimes these features have been re-created by the frontend UIs in this list and sometimes they haven’t. More than once since cancelling my subscription to the big providers, I’ve signed back up for a month or two to test out their latest features. Usually I find that whatever feature it was isn’t as valuable as I’d hoped and I return to using my frontend interface. </p></li>
<li><p><strong>You’ll need to invest time up front</strong> - There’s a little more work involved with getting this set up, but don’t let it intimidate you. You’ll need to sign up for API keys for the models you want to use, which is tedious since you’ll need to input your billing info for each one. If you want to add all the major models you’ll probably be looking at 30 minutes or so. But, you can dip your toe into this without commiting to connecting to 10 different LLM APIs. You can connect just one API, use the app for a bit, and decide whether you want to test a different one or add more more models.</p></li>
<li><p><strong>Less polish</strong> - I love the OpenAI UI and haven’t found an alternative chatbot UI that’s as visually pleasing, responsive, and organized. It’s not perfect, but I find myself wishing that one of these apps would just clone it and add folders and workspaces. Also, most of these chatbot UI apps are undergoing active development from small teams so they change quickly, things break, etc. These apps aren’t going through the same extensive product testing and validation processes Google, OpenAI, etc. are using before they release an update. </p></li>
<li><p><strong>Time spent tinkering</strong> - This is really an add on to item 3. Due to “lack of polish,” these apps tend to be more buggy and have more issues than you’re probably used to. Depending on whether you’re interested in learning new tech skills, you’ll find the time you spend setting this up and using it day to day to be a minor annoyance that doubles as a learning opportunity, or an intolerable inconvenience and waste of precious time. If you simply “need things to work” more than you’re interested in learning — about LLMs and tech in general — this may not be the right path for you.</p></li>
</ol>
<h2 id="about-this-list-of-llm-interfaces">About this list of LLM interfaces</h2>
<p>Before we jump into the list, let’s talk a bit about methodology, perspective, and biases. I’ve tried to pull out the pros and cons that seem important to someone looking for an LLM interface but, for instance, I’m not a coder, so I don’t have insight into which UI is best for software development and I don’t bother to review Cursor and other UIs specializing in code generation. </p><p>I take into account: </p><ul>
<li><strong>Cost / licensing</strong> - Most of the apps are free but I point out where some features are gated behind a paid plan. </li>
<li><strong>Tech savviness required</strong> - For instance, do you need to use or understand code?</li>
<li><strong>Installation process</strong> - Does it offer Docker installation or will you be installing dependencies via command line?</li>
<li><strong>Web-based or native app?</strong> Can it be run locally? Can it be self-hosted and accessed online? </li>
<li><strong>Ability to run local and API models?</strong> Does it integrate with ollama or similar?</li>
<li><strong>Mobile experience</strong> - Is it well-optimized for small screens?</li>
<li><strong>Audio experience</strong> - How does the TTS and STT experience measure up? I use OpenAI’s advanced speech mode as my comparison. </li>
<li><strong>My overall rating</strong> - This is where I attempt to rate each of these apps based on my overall experience with it. It’s not an average of all the other scores, or a ranking by the total of the scores, or anything like that. It’s just my opinion.</li>
</ul>
<p>I have no personal connection to the developers of these apps and I am not using any affiliate links or benefiting financially in any way. </p><p>If you have an app you’d like to see listed here, I’d love to try it, email me at: <a href="mailto:&#98;&#x72;&#x69;&#x61;&#110;&#103;&#x6c;&#97;&#100;&#x75;&#x40;&#x67;&#109;&#97;&#105;&#x6c;&#x2e;&#x63;&#x6f;&#109;">&#98;&#x72;&#x69;&#x61;&#110;&#103;&#x6c;&#97;&#100;&#x75;&#x40;&#x67;&#109;&#97;&#105;&#x6c;&#x2e;&#x63;&#x6f;&#109;</a>. If you’re the developer of one of these apps and you’d like to discuss something I’ve said here, I’d love to chat! Don’t hesitate to email me. </p><h1 id="browser-based-solutions">Browser-based solutions</h1>
<p>These apps can be exposed to the web or they can be locally accessed (via a browser). They often install via Docker. If you aren’t already using Docker apps, I highly recommend you dip your toe into it! It opens up a world of open source software and it really isn’t as technically challenging as it may appear. In fact, the whole point of it is to make setting up and using apps easier. That’s a topic for a different post though. </p><h2 id="openwebui"><a href="https://github.com/open-webui/open-webui">openwebui</a></h2>
<p><a href="https://github.com/open-webui/open-webui">Github stars: 70k</a>  |  <a href="https://docs.openwebui.com/roadmap/">Roadmap</a></p><blockquote>
<p>TL;DR: Openwebui’s standout feature is its community of user-created functions (that are used to add custom functionality). It’s popular because it’s one of the best chatbot UI’s available at the moment. </p></blockquote>
<p>One of the better-known AI interfaces, openwebui is also one of the most powerful and full-featured. It’s extensive feature set includes memory management, support for TTS and STT (audio), workspaces (which allow you to specify custom instructions), tags and folders for conversation management, and more. </p><p>It’s a web app that can be run locally (you’ll still access it via a browser window). It can be set up via Docker, which can make the installation process much faster and less error-prone for the less technical. </p><p>OpenwebUI’s major, standout strength is its community and extensibility. A <a href="https://openwebui.com/">web-based community portal</a> offers a collection of community-developed custom functions that add functionality and capabilities. It also offers a companion app, <a href="https://github.com/open-webui/pipelines">Pipelines</a>, for adding major functionality like supporting new model providers. I imagine for a developer, the openness and extensibility of openwebui is a lot of fun. For me, a non-developer, it can sometimes be challenging. Functions or Pipelines I install from the community don’t always work or are buggy. This can give the app an unpolished or unstable feel that I find unpleasant since I use AI constantly throughout the day at work and at home. If you need it to “just work” you might find a vanilla installation works great but some of the community functions cause issues. </p><p>The UI itself is good, but not great. The mobile UI especially could use some optimization. Folders were added recently which is a huge step up from the tags-only organization system it had before. Visually, the folder icons are quite small which is an odd design choice I’m seeing more and more. Also, in other apps you’re able to add custom instructions onto folders, but openwebui does not currently offer that. </p><table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td>Price</td>
<td>Free</td>
</tr>
<tr>
<td>Open source?</td>
<td>Yes</td>
</tr>
<tr>
<td>Technical skills required</td>
<td>Docker</td>
</tr>
<tr>
<td>Installation</td>
<td>Docker</td>
</tr>
<tr>
<td>Browser-based or native?</td>
<td>Browser</td>
</tr>
<tr>
<td>Run local models?</td>
<td>Yes</td>
</tr>
<tr>
<td>Mobile experience</td>
<td>3/5</td>
</tr>
<tr>
<td>Audio experience</td>
<td>3/5</td>
</tr>
<tr>
<td>Overall rating</td>
<td>4/5</td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
</tbody></table>
<h3 id="standout-features">Standout features:</h3>
<ul>
<li>A large community of many user-created custom functions (plugins) is openwebui’s “killer feature” you won’t find anywhere else. </li>
<li>Create multiple workspaces for separation and shared context between conversations</li>
<li>Speech support. Many frontend UI’s for AI don’t offer this. It’s not up to OpenAI’s Advanced Voice mode, yet. There’s a signficant delay between what you say and the LLM’s response. Also, no interruption (or even listening) while the LLMs response is being read.</li>
<li>Memory support that works similarly to OpenAI’s though out of the box you’ll need to click an “add to memory” button. There are also “autolearning” functions available via the community but I haven’t gotten these to work reliably yet.</li>
</ul>
<h3 id="weaknesses">Weaknesses:</h3>
<ul>
<li>Conversation organization</li>
<li>Speech mode is far behind what the frontier models are offering</li>
<li>Community functions aren’t well-curated - can be buggy and unreliable</li>
</ul>
<h2 id="chatbotui">chatbotui</h2>
<p><a href="https://github.com/mckaywrigley/chatbot-ui">29.6k github stars</a> | Not maintained</p><p>This entry will be short and it pains me that it is. What began as one of the most promising interfaces seems to have become an abandoned project. It’s still second only to the OpenAI UI in my mind. You can still set it up and use it, it just hasn’t kept pace with the rapid developments in the space. If you just want to have conversations with a chatbot and organize your threads into folders, this might be a great app for you. Just be aware that no one is patching security holes or adding new features at this time. One of the unfortunate downsides to the open source software scene is that isn’t uncommon. </p><p>If you find an app you like, look for an opportunity to donate to the developers. It really, really does make a difference. </p><h1 id="options-that-run-locally">Options that run locally</h1>
<p>These apps don’t require Docker or touching a command line tool so they’re a great option for anyone who just wants to get up and running with an API frontend without learning something new. </p><p>I do encourage you to learn Docker and get experience using command line tools. Neither is as intimidating or difficult as they may seem. You’ll need patience more than technical skills or intelligence. </p><h2 id="msty"><a href="https://msty.app/">msty</a></h2>
<p>Not on github &amp; not open source
Free, with some perk-like features accessible with a one-time payment</p><p>I find myself using both Msty and OpenWebUI a lot. They offer similar features and they’re both powerful — you can tweak as many model parameters as you like. They both make it really easy to use a combinaton of local models (via ollama) and proprietary models (via APIs). It’s really cool comparing the output from some of the smaller open source models to the output of the bleeding edge models. </p><p>Msty stands out in my mind as having a better folder and conversation organization system than openwebui (you can add custom instructions onto folders so that all conversations created in that folder are given context for that topic/project), it has better model comparison tools (you can send the same prompt to 2 or more models at once, split off conversations, and more. </p><p>While I’m comparing it to openwebui, I should point out one of openwebui’s strengths – its openness. There’s a large community of openwebui who contribute functions which are basically customizations or enhancements or even new features. It can be hit or miss on how buggy they are, but overall it’s a nice, signficant advantage openwebui has over msty, as a closed source product, will likely never have. </p><p>There are also some cool features you won’t see anywhere else like the ability to dig deeper into key words. It’s free, but there is a paid option that gives you early access to new features and unlocks some bells and whistles. Some companies aggressively gate their best features behind paid plans but Msty gives you even its most powerful features free. You’d get the paid plan mostly to support its development vs upgrading because you need access to this or that feature to get your work done. I really like that approach. </p><p>I do wish Msty was snappier. For an app running natively and locally, I expect it to be extremely responsive but it isn’t, at times. For instance, when switching between workplaces. Even smaller operations like switching between conversations feels just a titch laggy. </p><p>Another criticism would be that I think the UI could use some work. I’m not sure if it’s a new design trend or what, but a lot of LLM frontend apps use very small icons for the folders. This is unintuitive to me because in my mind folders should be bigger (since, they’re collections of all the files within them). It just goes against what I expect for folders to be visually smaller than files. It’s a small thing, but it bugs me. Another small nuisance that plagues me is that, even though it can be customized and tweaked in some ways, I can’t get the typography to feel quite right. There are other UI elements that could use some tweaking and polish in my mind. None of them is a dealbreaker and it’s unfair of me to mention so many slight imperfections for Msty and gloss over some much more significant ones in other apps. Just take into account that I use it a lot so it’s imperfections bug me more often and are more top of mind. </p><p>It’s a great app and the fact that I use it more than any other says a lot and reveals my opinion better than my focus on its minor flaws. </p><h2 id="jan"><a href="https://jan.ai/">jan</a></h2>
<p>Jan is an interesting app because if you fit its use case it’s perfect, but more advanced users will find it unuseable. </p><p>It’s available for Mac, Windows, and Linux. It makes running local models really easy. There’s a tab where you can quickly browse and download new models. It even warns you if a model is likely to struggle running on your system. In settings, you’re able to add API keys for a solid list of hosted providers. If that’s all you’re looking for, this is probably a really solid choice. </p><p>However, if you’re looking for pretty much any power feature — like folders, memory management, side-by-side conversations, or even access to advanced model parameter settings — this probably isn’t the app for you. </p><p>It feels snappy and polished. It looks like new features are well-planned and well-execuated. It’s one of those apps that feels like it was created by a thoughtful, passionate developer. </p><p>But without more advanced features and functionality, I think it will rarely be at the top of anyone’s list. The features it lacks are kind of essential for anyone who is using LLMs professionally, interested in prompt engineering, etc. </p><h2 id="lm-studio">LM studio</h2>

            ]]>
        </content>
    </entry>
</feed>
